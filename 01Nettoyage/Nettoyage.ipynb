{
 "cells": [
  {
   "cell_type": "raw",
   "id": "974456a1-f0e2-4864-9aee-58632108367c",
   "metadata": {},
   "source": [
    "Pour que les données soient optimales il faut effectuer un nettoyage de celles-ci:\n",
    "    Pour cela on peut vérifier leur exhaustivité, c'est-à-dire que toutes les \"features\" ont une valeur, ici il faudra éviter la ligne vide.\n",
    "    Il faut vérifier leur qualité, pour notre cas des messages en français sans caractère étrangers,  etc.\n",
    "    \n",
    "    Pour ce faire on procède de telle façon:\n",
    "            - Inspection primaire des données dans lesquelles il faut détecter les éventuelles surprises et résultat non souhaités.\n",
    "            - On tente ensuite de fixer ces éventuels problèmes.\n",
    "            - Il faut procéder à une vérification du résultat.\n",
    "            - Il peut être utile de procéder à la fabrication d'un rapport sur les changements effectuer.\n",
    "            \n",
    "    Pour la suite on proposera quelques normalisations et piste de fixe pour les données, ici comme les données proviennent d'un réseau social, il y aura des fautes d'orthographe et de grammaire, de l'argot, voir des langues étrangères, des données superflues comme des url, images, des smileys, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075403c9-ba48-4aa7-a3c7-97e3ab9aad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "deb0b872-2225-4743-b8e8-2308f13237ab",
   "metadata": {},
   "source": [
    "1. Ligature:\n",
    "    Bien que les ligatures soient des caractères normaux en français, leur utilisation sur les réseaux sociaux est peu fréquente et pourrait confondre les procédures d'apprentissage. Le plus simple est de les délier afin que le programme sache que les mots sont équivalents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf3fc1b-bbb3-4545-9ec3-b2f6b5a49d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rligature(w):\n",
    "    \"\"\"\n",
    "    Normalise les ligatures en lettres distinctes, à utiliser en fonction des lexiques et bibliothèques de mots utilisés.\n",
    "    :param w: une chaîne de caractères\n",
    "    :return: une chaîne de caractères sans œ et/ou æ\n",
    "    \"\"\"\n",
    "    if \"œ\" in w:\n",
    "        w = w.replace(\"œ\",\"oe\")\n",
    "    if \"æ\" in w:\n",
    "        w = w.replace(\"æ\", \"ae\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7b14fe-67d9-4a7a-97e0-47b63032aa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oeuf oeuf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rligature(\"œuf œuf\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b84f9971-73c1-44be-9087-9b9205b4d5dd",
   "metadata": {},
   "source": [
    "2. url:\n",
    "    Les url sont des liens vers les images jointes au tweet ou des liens vers d'autres contenus qui ne seront pas analysés dans notre cas. Elles sont donc un bruit inutile au traitement et peuvent être retirées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8147c684-3e68-411b-bc8a-6b159cf93e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhttp(w):\n",
    "    \"\"\"\n",
    "    normalise les urls\n",
    "    :param w: une chaîne de caractères\n",
    "    :return: une chaîne de caractères sans url\n",
    "    \"\"\"\n",
    "    if w.startswith(\"http\"):\n",
    "        w = \"\"\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514f3c3f-f745-4a90-b21a-e30bcf977633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhttp(\"http://monadresse.com\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ac07e65-6381-4206-95d0-1af1200c1321",
   "metadata": {},
   "source": [
    "3. Caractères spéciaux:\n",
    "    Tous les caractères qui ne sont pas utiles pour le français ne sont pas significatifs (les smileys ont quant à eux des significations peu clair), on conservera alors tout ce qui est dans :  [a-zA-Z0-9àâäéèëêïîôöùûüÿç ;.,?!+-/*=]et le reste sera nettoyé:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2a09e3-6751-4f5a-9e08-3be43e724138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rexochar(w):\n",
    "    \"\"\"\n",
    "    normalise en retirant tous les caractères exotiques du point de vue de la langue française\n",
    "    :param w: une chaîne de caractères\n",
    "    :return: une chaîne de caractères sans caractères spéciaux\n",
    "    \"\"\"\n",
    "    temp = re.sub('[^a-zA-Z0-9àâäéèëêïîôöùûüÿç ;.,?!+-/*=]+', '', w)\n",
    "    if (temp != w):\n",
    "        w = temp\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595d54cd-9cad-48fd-9f94-41c731985b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  ca va ?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rexochar(\"בוקר טוב ca va ?\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58dea366-39e2-435d-a2bd-de1d22680961",
   "metadata": {},
   "source": [
    "4. Utilisation d'un lexique:\n",
    "    Pour conserver que des mots bien orthographiés on peut envisager l'utilisation d'un lexique (ici \"liste.de.mots.francais.frgut.txt\" ), le procéder nécessitera donc qu'on charge la liste des mots avec load_data(), ensuite il faut effectuer des comparaisons avec le mot étudié.\n",
    "    Cette pratique à l'inconvénient d'être plutôt lourde et très destructrice, pour une meilleure pertinence elle devrait être combinée avec des calcules de distance et des techniques s'apparentant à du fuzzy matching, mais là encore le coût de fonctionnement sera très élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97b7dff-f5c6-487d-a09d-8eca7e03e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(f, d=0):\n",
    "        \"\"\"\n",
    "        Charge un fichier de donnée\n",
    "        :param f: nom du fichier\n",
    "        :return: liste\n",
    "        \"\"\"\n",
    "        with open(f, 'r', encoding=\"utf-8\") as f:\n",
    "                dt = f.read().splitlines()\n",
    "        return dt\n",
    "    \n",
    "lexique_fr = load_data(\"liste.de.mots.francais.frgut.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fee94c6-26f6-46b6-b372-3472497fd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rlexique(w, lex):\n",
    "    \"\"\"\n",
    "    Vérifie la présence d'un mot dans un lexique, si ce n'est pas le cas l'efface\n",
    "    :param f: nom du fichier\n",
    "    :return: liste\n",
    "    \"\"\"\n",
    "    if w.lower() not in lex:\n",
    "        w = \"\"\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf919195-bc3b-4d2f-bc0d-83cf5fb963a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlexique(\"anticastoriquement\", lexique_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767babf9-3a4c-47e8-b9eb-7f04134c7b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bonjour'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlexique(\"bonjour\", lexique_fr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33fc55ce-9a16-4e91-88e4-5cd96e317753",
   "metadata": {},
   "source": [
    "5. Utilisation de stopwords:\n",
    "    Les mots qui ont une fréquence d'apparition trop importante ne permettent pas à un apprentissage non supervisé d'en tirer un sens utile, il est alors préférable de les retirer. Il existe une liste standard de stopwords français avec spacy et fr_core_news_sm, sinon il est possible de produire sa propre stop liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d01997-46ae-4730-8dda-491993e8ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "stopWords = set(stopwords.words('french'))\n",
    "def rstopWords(w, stop):\n",
    "    \"\"\"\n",
    "    Vérifie si un mot est dans une stopliste ou non\n",
    "    :param f: name of the file\n",
    "    :return: array of array\n",
    "    \"\"\"\n",
    "    if w in stop:\n",
    "        w = \"\"\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f9f775-8aa2-43d6-93fc-f5fe71be2fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rstopWords(\"est\", stopWords)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b84387d5-4376-495b-8c7d-b15bf85a6430",
   "metadata": {},
   "source": [
    "6. Corrections ciblées:\n",
    "    Les fautes de frappes, d'orthographe et de grammaire sont un obstacle important à l'utilisation d'apprentissage non supervisé, d'autant plus si l'on explore la voie syntaxique. \n",
    "    Pour la grammaire, il faudrait donc corriger la justesse du français employé ce qui n'est pas mince à faire et pourrait passer par l'usage d'un correcteur automatisé, pour l'orthographe, tel que vue précédemment, il est envisageable d'utiliser un lexique. Toutefois, ces deux solutions engendrent un coût de fonctionnement important.\n",
    "    Une solution mitigée pourrait être une correction ciblée des termes importants en ce qui concerne la recherche effectuée.\n",
    "    On pourrait alors pratiquer un calcul de distance entre les termes parcourus et ceux recherchés afin de les remplacer par un mot unique à l'image d'un Fuzzy matching:\n",
    "    \n",
    "                                                        Gender   male  female\n",
    "                                                         m         3      5\n",
    "                                                         Male      1      3\n",
    "                                                         fem.      5      3\n",
    "                                                         FemalE    3      2\n",
    "                                                         Femle     3      1\n",
    "                                                        \n",
    "    Mais dans notre cas le nombre de mots recherchés serait très important et la procédure extrêmement couteuse et confuse avec des distances vers un trop grand nombre de mots possibles.\n",
    "    Il reste alors la solution d'un simple remplacement par un mot unique pour tous les mots semblables comportant des fautes et ne pouvant pas être un autre mot correct:\n",
    "    (avec une liste dont l'élément 0 et l'élément de référence et les autres des variantes erronées possibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "351103ca-e9e7-4f62-a1c8-6e80c00ffdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remplacement = [[\"catalogue\", \"tacalogue\", \"catalog\", \"katalog\", \"katalogue\"]]\n",
    "w = \"catalog\"\n",
    "def rplace(w, liste):\n",
    "    for e in liste:\n",
    "        if w in e:\n",
    "            w = e[0] \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be42d684-b3f5-47ac-81bb-3024e819b3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catalogue'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rplace(w, remplacement)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0582009d-1860-492f-be05-addb321ce36f",
   "metadata": {},
   "source": [
    "7. lemmatisation:\n",
    "Traitement lexical apporté à un texte en vue de son analyse. Ce traitement consiste à appliquer aux occurrences des lexèmes sujets à flexion (en français, verbes, substantifs, adjectifs), c'est une généralisation de genre, de nombre, de personne comme:\n",
    "    petit, petite, petits, petites -> petit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a2ecf2f-917d-45a6-b51e-493aeb6a3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coupure', 'coupure', 'couper']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = \"coupures coupure coupé\"\n",
    "lemma = [X.lemma_ for X in nlp(w)]\n",
    "lemma"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e38e339-132f-460a-97c2-81aaeb40ea8d",
   "metadata": {},
   "source": [
    "8. Stemming:\n",
    "Racinisation vise à garder la racine du mot:\n",
    "continu, continua, contination, continue -> continu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79eab0fc-c764-46cf-8905-4499f11817be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coupur', 'coupur', 'coup']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = \"coupure coupure couper\"\n",
    "stemmer = SnowballStemmer(language='french')\n",
    "result = [stemmer.stem(X.text) for X in nlp(w)]\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
