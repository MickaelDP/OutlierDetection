{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c57c5e4-f90b-4897-89a9-a8cc7778d8bb",
   "metadata": {},
   "source": [
    "# Présentation du POS tagging et chunking\n",
    "---\n",
    "_Démonstration simple en français avec la librairie spacy_\n",
    "\n",
    "---\n",
    "\n",
    "  1. POS tagging\n",
    "  2. Chunking\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fcde5-c1eb-453c-aca2-4874c8d66ca1",
   "metadata": {},
   "source": [
    "### 1. POS tagging\n",
    "- importation des libraries nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f336178-7068-4a45-8195-1e6aa3e6cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ab012-0f88-443f-a8a3-62fb89626cc2",
   "metadata": {},
   "source": [
    "_Chargement des règles de découpage et de taggage à partir du mode fr_core_news (https://spacy.io/models/fr)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7a0709-a21d-40a1-9ff0-b820704de1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b6c63-eadd-428b-af03-5174fdc24471",
   "metadata": {},
   "source": [
    "_Application des tags à un exemple_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd7b26e-dd79-45e8-a5e3-60bee2119be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"Bonjour comment allez vous ?\"\n",
    "nlp_sentence = nlp(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be44444-e96f-4ce9-a092-1fbc54f91047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mot: Bonjour tag: PROPN\n",
      "mot: comment tag: ADV\n",
      "mot: allez tag: VERB\n",
      "mot: vous tag: PRON\n",
      "mot: ? tag: PUNCT\n"
     ]
    }
   ],
   "source": [
    "for e in nlp_sentence:\n",
    "    print(f\"mot: {e} tag: {e.tag_}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289f4e5-11ec-47c3-8e5c-70799d90241a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Chunking\n",
    " _- découpe du texte en phrases_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4458a1-dcc3-42b1-a33d-912219f8190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voila mes parents.\n",
      "Ils sont très heureux d'être ici.\n"
     ]
    }
   ],
   "source": [
    "exemple = nlp(\"Voila mes parents. Ils sont très heureux d'être ici.\")\n",
    "for phrase in exemple.sents:\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7bc3f-286f-4696-ab61-2a13fa622a90",
   "metadata": {},
   "source": [
    "_- Extraction des composantes nominales des phrases du texte:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b84bb40-8486-4178-b7aa-d43213034438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voila  -  NP\n",
      "mes parents  -  NP\n",
      "Ils  -  NP\n"
     ]
    }
   ],
   "source": [
    "for chunk in exemple.noun_chunks:\n",
    "    print(chunk.text, \" - \", chunk.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f38a0d-372e-4324-b3d8-d03d2d56cb96",
   "metadata": {},
   "source": [
    "_- Extractions des composantes verbales qui nécessite plus de configuration_\n",
    "\n",
    "_Il sera fait appelle à la librairie textacy qui effectue des tâche de NLP comme du nettoyage en amont et aprés l'usage de Spacy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a58084-f960-4314-b41e-9e3c17266401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970ed9f-ae39-45ac-9b17-d302757a3f83",
   "metadata": {},
   "source": [
    "_Il est nécessaire de décrire les patterns qui nous interesse dans ce cas la:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb6a565-bd2d-4ede-b14e-30e0aabb4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"POS\": \"ADV\"}, {\"POS\": \"VERB\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58e3444-6879-4c7e-afc2-fb249f48e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_phrases1 = textacy.extract.token_matches(exemple, patterns=pattern)\n",
    "verb_phrases2 = textacy.extract.token_matches(nlp_sentence, patterns=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a063b2a9-a211-42b3-b930-0515260336e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verb_phrase2: comment allez\n"
     ]
    }
   ],
   "source": [
    "for verb_p in verb_phrases1:\n",
    "    print(f\"verb_phrase1: {verb_p}\")\n",
    "for verb_p in verb_phrases2:\n",
    "    print(f\"verb_phrase2: {verb_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120c4cb-6ac5-4da3-8bb4-c3a5950e1161",
   "metadata": {},
   "source": [
    "_Toutes les formes de phrases ne correspondant pas au patterns décrit seront alors ignoré_\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
